{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Random Fields (CRF)\n",
    "## Introduction\n",
    "\n",
    "In this notebook we're gonna attempt to train a CRF model and use it to identify Named Entities. In the last notebook (HMM), we trained a Hidden Markov Model, which is a generative model based on directed graphs, to identify Named Entities. Now we're gonna try out a more generalized model which is based on undirected graph. \n",
    "\n",
    "In this specific case, we are going to see the Linear-chain CRF which is a special case of CRF very similar to HMM. In fact, we may consider HMM as a special case of a linear-chain CRF. The graph in a linear-chain CRF, just as HMM is a sequence of nodes that produce symbols, but the difference is that CRF take into account the whole set of observations to produce the symbols. \n",
    "\n",
    "The library that we are going to use is the sklearn-crfsuite (http://sklearn-crfsuite.readthedocs.io/), which is a sklearn wrapper over the origin crfsuite library http://www.chokkan.org/software/crfsuite/ implemented in C++. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Review of CRF\n",
    "\n",
    "Before getting into the code, let's just review the CRF definition and how to train it.\n",
    "\n",
    "### CRF definition\n",
    "\n",
    "(Summary based on this paper: https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf )\n",
    "\n",
    "The intuition behind the CRF is that we can estimate p(x|y) directly instead of going through p(x,y). CRF does this by using feature-functions that consider the transition between the two states $y_t, y_{t-1}$ and a vector $\\boldsymbol{x_t}$ containing all the global components of $\\boldsymbol{x}$ (aka features) that are needed to compute the feature function at time t. These feature-functions return a real number which is then multiplied by a weight parameter $\\lambda_k$.\n",
    "\n",
    "\n",
    "The formal definition is:\n",
    "\n",
    "$$ p(x|y) = \\frac{1}{Z(x)}\\exp[\\sum_{k=1}^{K}\\lambda_k f_k(y_t, y_{t-1}, \\boldsymbol{x_t} )  ]   $$\n",
    "where Z(x) is a normalizing factor defined:  \n",
    "$$ Z(x) = exp[\\sum_y \\lambda_k f_k(y_t, y_{t-1}, x_t )   ]  $$\n",
    "\n",
    "Note that the feature functions can be virtually anything, but commonly they are defined as product of binary functions that indicate the presence or absence of an attribute. In which case the functions might take this form:\n",
    "\n",
    "$$ F_j(x,y) =  A_a(x) B_b(y) $$ \n",
    "where the subscript $a$ indexes a set of functions of $x$ and $b$ indexes a set of functions of $y$.\n",
    "\n",
    "For example there could be a set of indicator functions of x:\n",
    "- $A_1(x) = I(x$ starts with a Capital Letter$)$\n",
    "- $A_2(x) = I(len(x) > 6)$\n",
    "- $A_3(x) = I(x$[0:4] == 'Wash'$)$\n",
    "\n",
    "(source: http://cseweb.ucsd.edu/~elkan/250Bwinter2012/loglinearCRFs.pdf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Estimation (training)\n",
    "So, for constructing the model we have the labels or y values (which would be the tags), the x values or the features,\n",
    "and the feature functions which are defined arbitrary (it could be a product of indicator functions). What's missing are the $\\lambda$ parameters (or weights). These $\\lambda$ values are important since they determine how relevant a feature function is. \n",
    "\n",
    "For completing the model we are going to estimate the parameters (aka train the model) using the traditional Maximum Likelihood.\n",
    "\n",
    "We can frame the task as: given a set of training samples, find the parameter values $\\lambda_k$ that maximize the conditional probability of the samples. In other words, the goal is to find the $\\lambda_k$  maximize the log likelihood or conditional log likelihood with an added regularization term (i.e. to smooth).\n",
    "\n",
    "$$ \\boldsymbol\\lambda^* = \\arg_{\\lambda} min L(\\boldsymbol\\lambda|x) + C\\frac{1}{2}||\\lambda^2|| $$\n",
    "\n",
    "where \n",
    "\n",
    "$$L(\\boldsymbol\\lambda| x) =- log \\prod_{i=1}^{N}  p(y^{(i)}| x^{(i)}; \\lambda ) = -\\sum_{i=1}^{N}log  p(y^{(i)}| x^{(i)};\\lambda )$$\n",
    "\n",
    "**This function is convex i.e. with no local minimums**  so we can use gradient based methods like Stochastic Gradient Ascent. The difficulty is that in order to do it, it is necessary to calculate all the partial derrivatives with respect to each feature function, thus making it computationally expensive. One solution is to use the forward-backward algorithm to estimate the partial derivatives.\n",
    "\n",
    "There are also other alternatives to estimate the parameters using Newtowns Method to converge faster or quasi-Newtown methods such as BFGS or L-BFGS. There's also an interesting alternative using a perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (Predicting)\n",
    "\n",
    "Finally, having the model complete the last step is to use it to predict labels. This is, finding the labels that maximize the conditional probability:\n",
    "$$ \\boldsymbol y^âˆ— = \\underset{y}{\\operatorname{argmax}} p(y|x) $$\n",
    "\n",
    "Since we are working with linear-chain CRF then a variation of dynamic-programming algorithms used for HMM can be employed. A popular algorithm is the recursive Viterbri algorithm. The recursive part is defined as:\n",
    "\n",
    "$$ \\delta_t(j) = \\underset{i \\in S}{\\operatorname{max}} \\Psi_t(j,i, x_t)\\delta_t(i) $$\n",
    "\n",
    "where $t$ is the time-step, j is the current state, S is the set of all states, $\\Psi_t$ is a way to write the set of feature functions at time step $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "Now that we've reviewed the CRF definition, we're going to code. Specifically we are going to follow the tutorial from the sklearn-crfsuite but with small twists and changes to check if we really are learning how to use it.\n",
    "\n",
    "The tutorial is from this site: http://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the libraries for the project\n",
    "import pandas as pd\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import conll2002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset\n",
    "First we are going to import the datasets. For this tutorial we are using the spanish set of Conll2002, which conviniently has the train and test datasets splitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train sentences: 8323\n",
      "Number of test sentences: 1517\n"
     ]
    }
   ],
   "source": [
    "train_sents = list(conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(conll2002.iob_sents('esp.testb'))\n",
    "\n",
    "print \"Number of train sentences: %i\" %len(train_sents)\n",
    "print \"Number of test sentences: %i\" %len(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just have a sneak peek to the data to get an idea of how the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Melbourne', u'NP', u'B-LOC'),\n",
       " (u'(', u'Fpa', u'O'),\n",
       " (u'Australia', u'NP', u'B-LOC'),\n",
       " (u')', u'Fpt', u'O'),\n",
       " (u',', u'Fc', u'O'),\n",
       " (u'25', u'Z', u'O'),\n",
       " (u'may', u'NC', u'O'),\n",
       " (u'(', u'Fpa', u'O'),\n",
       " (u'EFE', u'NC', u'B-ORG'),\n",
       " (u')', u'Fpt', u'O'),\n",
       " (u'.', u'Fp', u'O')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see each sentence is composed by a list of tuples. Each tuple has three fields: \n",
    "1. **Word**: This is the actual word in the sentence.\n",
    "2. **Part-of-Speech tag (POS)**: It indicates the \"role\" of the word in the sentence\n",
    "3. **IOB Named entity tag** : A tag that shows which words are part of a named entity and their entity type using the Inside Outside Beginning (IOB) notation. The IOB notation basically has two parts: \n",
    "    - The first letter indicates if the word is the beggining of an entity (B), the inner part of an entity (I) or if it's a word outside the entitities (O).\n",
    "    - Then the word following the dash (-) indicates the entity type. For example, LOC means that the entity is a location.\n",
    "    \n",
    "    \n",
    "For this tutorial we are trying to figure out the IOB tags in order to extract the named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "The next step is to create a set of features from the original dataset to feed the training algorithm with rich information. \n",
    "\n",
    "The tutorial gives a nice implementation for generating the features with the sent2features and word2features functions. Since I don't want to just copy the code I'm gonna rewrite those functions in another way to get the concept right.\n",
    "\n",
    "The basic idea is to generate an List of Lists with dictionary objects that contain all the feature values. Conviently using dictionaries allow us to feed the trainer with only the relevant features at each step. Recall the CRF definition\n",
    "> CRF does this by using feature-functions that consider the transition between the two states $y_t, y_{t-1}$ and a vector $\\boldsymbol{x_t}$ containing all the global components of $\\boldsymbol{x}$ (aka features) that are needed to compute the feature function at time t.\n",
    "\n",
    "Notice in the code below that for the first word in a sentence we don't use some features based on the preceding word (for obvious reasons) and for the rest of the words they don't have the \"first_word\" feature. This is our implementation for this example, but actually we can define features using any component or from the whole sequence if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getXY(sentences):\n",
    "    feature_sents = []\n",
    "    labels = []\n",
    "    for sent in sentences:\n",
    "        f_sent = []\n",
    "        for idx, item in enumerate(sent):\n",
    "            word = item[0]\n",
    "            pos_tag = item[1]\n",
    "            \n",
    "            features = {\n",
    "                'word': word.lower(),  #the word itself\n",
    "                'suffix_3': word[-3:], #the word suffix \n",
    "                'suffix_2': word[-2:], #the word suffix \n",
    "                'upper': word.isupper(),\n",
    "                'title': word.istitle(), #True if the first word is upper but the rest is lower\n",
    "                'digit': word.isdigit(),\n",
    "                'postag': pos_tag,\n",
    "                'postag_base': pos_tag[:2],\n",
    "            }\n",
    "            \n",
    "            if idx == 0:                \n",
    "                features['first_word'] = True\n",
    "            else:\n",
    "                word_1 = sent[idx-1][0]\n",
    "                postag_1 = sent[idx-1][1]\n",
    "                \n",
    "                features.update({\n",
    "                    \"word_1\": word_1.lower(),\n",
    "                    'word_1_title()': word_1.istitle(),\n",
    "                    'word_1_upper': word_1.isupper(),\n",
    "                    'word_1_postag': postag_1,\n",
    "                    'word_1_postag_base': postag_1[:2],  \n",
    "                })\n",
    "            \n",
    "            if idx == len(sent) - 1:\n",
    "                features[\"last_word\"] = True\n",
    "            #append the features to the sentence\n",
    "            f_sent.append(features)\n",
    "            \n",
    "        #append the sentences to the list\n",
    "        feature_sents.append(f_sent)\n",
    "        #apend labels \n",
    "        labels.append( [ label for w,p,label in sent  ] )\n",
    "        \n",
    "    return feature_sents, labels    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the function to get the features and label lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = getXY(train_sents)\n",
    "X_test, y_test = getXY(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just visualize one item of a sentence to see check the result:    \n",
    "**(Notice that the first and second have different features)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'digit': False,\n",
       " 'postag': u'Fpa',\n",
       " 'postag_base': u'Fp',\n",
       " 'suffix_2': u'(',\n",
       " 'suffix_3': u'(',\n",
       " 'title': False,\n",
       " 'upper': False,\n",
       " 'word': u'(',\n",
       " 'word_1': u'melbourne',\n",
       " 'word_1_postag': u'NP',\n",
       " 'word_1_postag_base': u'NP',\n",
       " 'word_1_title()': True,\n",
       " 'word_1_upper': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first word of sentence 0\n",
    "X_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'digit': False,\n",
       " 'postag': u'Fpa',\n",
       " 'postag_base': u'Fp',\n",
       " 'suffix_2': u'(',\n",
       " 'suffix_3': u'(',\n",
       " 'title': False,\n",
       " 'upper': False,\n",
       " 'word': u'(',\n",
       " 'word_1': u'melbourne',\n",
       " 'word_1_postag': u'NP',\n",
       " 'word_1_postag_base': u'NP',\n",
       " 'word_1_title()': True,\n",
       " 'word_1_upper': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second word of sentence 0\n",
    "X_train[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I-LOC'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Ok, now the fun part: Training the model. Since this specific library provides an API compatible to sklearn this part is really easy.\n",
    "\n",
    "We just instantiate the classifier and then we fit (train) the data as any classifier in sklearn.\n",
    "\n",
    "The parameters for the Classifier are:\n",
    "- **algorithm**: The parameter estimation algorithm to use. For this tutorial we are using the lbfgs. \n",
    "- **c1**:The coefficient for L1 regularization applied to the lbfgs.\n",
    "- **c2**:The coefficient for L2 regularization applied to the lbfgs\n",
    "- **max_iterations**: Limits the number of iterations for the optimization algorithms.\n",
    "- **all_possible_transitions**: generates transition features that don't occur in the dataset.\n",
    "\n",
    "There are other parameters which are described here: \n",
    "http://sklearn-crfsuite.readthedocs.io/en/latest/api.html\n",
    "\n",
    "We are also going to check the other parameters later in this notebook. Right now we just need to learn how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.7 s, sys: 416 ms, total: 40.1 s\n",
      "Wall time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's check how the classifier performs with the test data.  Since we are just interested on the named entities we are going to only include the B and I labels in the score.\n",
    "\n",
    "Notice that for scoring we are using the flat_classification_report() method that comes in the sklearn_crfsuite.metrics module. This method prints exactly the same output as the sklearn classification_report(), but as input it receives a List of Lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.803     0.759     0.780      1084\n",
      "     B-MISC      0.700     0.537     0.608       339\n",
      "      B-ORG      0.813     0.838     0.825      1400\n",
      "      B-PER      0.817     0.865     0.841       735\n",
      "      I-LOC      0.695     0.637     0.665       325\n",
      "     I-MISC      0.661     0.542     0.596       557\n",
      "      I-ORG      0.840     0.799     0.819      1104\n",
      "      I-PER      0.880     0.938     0.908       634\n",
      "\n",
      "avg / total      0.797     0.777     0.786      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#prepare the labels by removing the O labels\n",
    "labels = list(clf.classes_)\n",
    "labels.remove('O')\n",
    "print metrics.flat_classification_report(y_test, y_pred, labels=sorted(labels), digits=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can observe the model performs well with the initial parameters and the simple features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "Ok, so now that we know how to train and test the model, let's improve the model by tuning it's hyper parameters. \n",
    "\n",
    "For this, we will use a CVGridSearch provided by the sklearn library. (Good thing that this CRF is compatible with sklearn). \n",
    "\n",
    "First we are going to create a function that we can re-use to test various parameters. The function will create a scorer (f1 scorer with only the labels of our interest), instantiate and train the model using CVSearchGrid and  print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#re-usable function to train and tune the classifier.\n",
    "def train_tune_classifier(parameters, X, y, verbose=1):\n",
    "    #scorer\n",
    "    f1_scorer = make_scorer( metrics.flat_f1_score,\n",
    "                             average='weighted', labels=labels)\n",
    "    #model instance\n",
    "    crf = sklearn_crfsuite.CRF()\n",
    "\n",
    "    clf = GridSearchCV(crf, parameters, scoring=f1_scorer, cv=4, n_jobs=4, verbose = verbose )\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    #print results\n",
    "    print \"Best Parameters: %s\" %clf.best_params_\n",
    "    print \"Best Score: %0.4f\" %clf.best_score_\n",
    "\n",
    "    #dataframe with detailed results \n",
    "    params = clf.cv_results_[\"params\"]\n",
    "    df = pd.DataFrame({\n",
    "            \"params\": [ \", \".join([str(param[x]) for x in param]) for param in params ],\n",
    "            \"mean_train_score\": [x for x in clf.cv_results_[\"mean_train_score\"]],\n",
    "            \"mean_test_score\": [x for x in clf.cv_results_[\"mean_test_score\"]],\n",
    "            \"mean_score_time\": [x for x in clf.cv_results_[\"mean_score_time\"]],\n",
    "            \"mean_fit_time\": [x for x in clf.cv_results_[\"mean_fit_time\"]]\n",
    "        }).sort_values(by=\"mean_test_score\",ascending=False)\n",
    "    \n",
    "    return clf, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter estimation algorithms\n",
    "\n",
    "Now that we have the function, we are going to test the different parameter estimation algorithms with their default hyper-parameters. Let's recall that the idea is to maximize the log likelihood and that there are various approaches to compute it. CRFSuite supports the following:\n",
    "- lbfgs: Gradient Descent using the Limited BFGS method.\n",
    "- l2sgd: Stochastic Descent using with a L2 regularization term (i.e. to smooth).\n",
    "- ap: Average Perceptron. \n",
    "- pa: Passive Agressive.\n",
    "- arow: Adaptive Regularization Of Weight Vector\n",
    "\n",
    "Let's run the code and see.. (if you are actually running this, grab a coffee , read the news cause it might take a while... oh and also expect this to consume some big portion of RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'algorithm': 'pa', 'max_iterations': 100}\n",
      "Best Score: 0.7579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.869644</td>\n",
       "      <td>0.646210</td>\n",
       "      <td>0.757869</td>\n",
       "      <td>0.967718</td>\n",
       "      <td>pa, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.214253</td>\n",
       "      <td>0.645312</td>\n",
       "      <td>0.756501</td>\n",
       "      <td>0.970804</td>\n",
       "      <td>ap, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.225473</td>\n",
       "      <td>0.963040</td>\n",
       "      <td>0.743637</td>\n",
       "      <td>0.880462</td>\n",
       "      <td>lbfgs, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.748841</td>\n",
       "      <td>1.443953</td>\n",
       "      <td>0.740227</td>\n",
       "      <td>0.882993</td>\n",
       "      <td>l2sgd, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.001748</td>\n",
       "      <td>0.621078</td>\n",
       "      <td>0.691417</td>\n",
       "      <td>0.967923</td>\n",
       "      <td>arow, 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3      20.869644         0.646210         0.757869          0.967718   \n",
       "2      19.214253         0.645312         0.756501          0.970804   \n",
       "0      32.225473         0.963040         0.743637          0.880462   \n",
       "1      33.748841         1.443953         0.740227          0.882993   \n",
       "4      18.001748         0.621078         0.691417          0.967923   \n",
       "\n",
       "       params  \n",
       "3     pa, 100  \n",
       "2     ap, 100  \n",
       "0  lbfgs, 100  \n",
       "1  l2sgd, 100  \n",
       "4   arow, 100  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters\n",
    "parameters = {\n",
    "    \"algorithm\": ['lbfgs','l2sgd','ap','pa','arow'],\n",
    "    \"max_iterations\": [100]\n",
    "}\n",
    "\n",
    "#tune\n",
    "clf, results = train_tune_classifier(parameters, X_train, y_train, verbose=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe the best scores are for the passive-agressive and the perceptron. Nevertheless they seem to be overfitting as the difference between train and test scores are larger than the ones for the gradient. \n",
    "\n",
    "Also, we can notice that the pa and ap algorithms are faster than the gradient based algorithms. So we are going to go with the passive-aggresive since it seems to be a good option in terms of score and time.\n",
    "\n",
    "## Passive-Aggresive\n",
    "\n",
    "The passive-aggresive algorithm is describe in this paper: http://www.jmlr.org/papers/volume7/crammer06a/crammer06a.pdf\n",
    "\n",
    "The intuition behind the passive-aggresive algorithm is fairly simple. The algorithm makes many rounds were it looks at each item of the sequence and makes a prediction. After the round finishes, it receives feedback about the predictions and updates the weights only when it made a mistake (aggresive part) and it does nothing if it made a correct prediction (the passive part). The model is noise-resistant with has two main algorithm variants (PA-I and PA-II).\n",
    "\n",
    "## Tuning with PA\n",
    "\n",
    "Ok now that we've selected a maximization algorithm, let's tune its hyper parameters. We are going to tune:\n",
    "\n",
    "- **pa_type**: The strategy for updating feature weights. There are three strategies\n",
    "    - 0: PA  without slack variables\n",
    "    - 1: PA-I\n",
    "    - 2: PA-II\n",
    "- **c**: Called the aggresiveness parameter it determines how \"aggresive\" the update step will be. (it only applies to PA-I and PA-II )\n",
    "- **error_sensitive**: If True, the algorithm includes the squared root of the incorrect labels.\n",
    "- **averaging**: If True, the algorithm computes the average of all weights at all update steps.\n",
    "\n",
    "First we are going to choose a pa_type using the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "[CV] pa_type=0, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=0, algorithm=pa, total=  21.0s\n",
      "[CV] pa_type=0, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=0, algorithm=pa, total=  20.3s\n",
      "[CV] pa_type=0, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=0, algorithm=pa, total=  20.7s\n",
      "[CV] pa_type=0, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=0, algorithm=pa, total=  20.8s\n",
      "[CV] pa_type=1, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=1, algorithm=pa, total=  21.7s\n",
      "[CV] pa_type=1, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=1, algorithm=pa, total=  21.3s\n",
      "[CV] pa_type=1, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=1, algorithm=pa, total=  20.0s\n",
      "[CV] pa_type=1, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=1, algorithm=pa, total=  20.7s\n",
      "[CV] pa_type=2, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=2, algorithm=pa, total=  20.9s\n",
      "[CV] pa_type=2, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=2, algorithm=pa, total=  21.5s\n",
      "[CV] pa_type=2, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=2, algorithm=pa, total=  21.6s\n",
      "[CV] pa_type=2, algorithm=pa .........................................\n",
      "[CV] .......................... pa_type=2, algorithm=pa, total=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:  5.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'pa_type': 0, 'algorithm': 'pa'}\n",
      "Best Score: 0.7590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.077897</td>\n",
       "      <td>0.637137</td>\n",
       "      <td>0.758975</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0, pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.953407</td>\n",
       "      <td>0.968848</td>\n",
       "      <td>0.758620</td>\n",
       "      <td>0.967618</td>\n",
       "      <td>1, pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.928580</td>\n",
       "      <td>0.609879</td>\n",
       "      <td>0.758512</td>\n",
       "      <td>0.967650</td>\n",
       "      <td>2, pa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score params\n",
       "0      20.077897         0.637137         0.758975          0.967500  0, pa\n",
       "1      19.953407         0.968848         0.758620          0.967618  1, pa\n",
       "2      19.928580         0.609879         0.758512          0.967650  2, pa"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters\n",
    "parameters = {\n",
    "    \"algorithm\": ['pa'],\n",
    "    'pa_type': [0,1,2],\n",
    "}\n",
    "\n",
    "#tune\n",
    "clf, results = train_tune_classifier(parameters, X_train, y_train, verbose=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score is the PA without the slack variables. Let's evaluate it on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.795     0.756     0.775      1084\n",
      "     B-MISC      0.688     0.566     0.621       339\n",
      "      B-ORG      0.815     0.836     0.825      1400\n",
      "      B-PER      0.809     0.878     0.842       735\n",
      "      I-LOC      0.740     0.640     0.686       325\n",
      "     I-MISC      0.696     0.562     0.622       557\n",
      "      I-ORG      0.854     0.794     0.823      1104\n",
      "      I-PER      0.881     0.937     0.908       634\n",
      "\n",
      "avg / total      0.803     0.780     0.790      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print metrics.flat_classification_report(y_test, y_pred, labels=sorted(labels), digits=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe we have improved the model by 0.004 on the f1 score. \n",
    "\n",
    "### Farther tuning ... \n",
    "\n",
    "Now we are going to tune the other parameters.   \n",
    "(Notice that we are not tuning the aggresiveness parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  22.7s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  22.8s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  22.6s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  22.5s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  21.4s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  22.1s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  21.1s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  21.6s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  20.8s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  20.9s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  21.4s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  20.6s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  21.9s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  22.1s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  20.1s\n",
      "[CV] averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=False, pa_type=0, error_sensitive=False, algorithm=pa, max_iterations=100, total=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  16 out of  16 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'averaging': True, 'pa_type': 0, 'error_sensitive': True, 'algorithm': 'pa', 'max_iterations': 100}\n",
      "Best Score: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.021102</td>\n",
       "      <td>0.625853</td>\n",
       "      <td>0.759988</td>\n",
       "      <td>0.967376</td>\n",
       "      <td>True, 0, True, pa, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.543878</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>0.757528</td>\n",
       "      <td>0.962168</td>\n",
       "      <td>True, 0, False, pa, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.268769</td>\n",
       "      <td>0.636548</td>\n",
       "      <td>0.719321</td>\n",
       "      <td>0.940795</td>\n",
       "      <td>False, 0, True, pa, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.257003</td>\n",
       "      <td>0.642844</td>\n",
       "      <td>0.711953</td>\n",
       "      <td>0.937266</td>\n",
       "      <td>False, 0, False, pa, 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      22.021102         0.625853         0.759988          0.967376   \n",
       "1      20.543878         0.995777         0.757528          0.962168   \n",
       "2      20.268769         0.636548         0.719321          0.940795   \n",
       "3      20.257003         0.642844         0.711953          0.937266   \n",
       "\n",
       "                     params  \n",
       "0    True, 0, True, pa, 100  \n",
       "1   True, 0, False, pa, 100  \n",
       "2   False, 0, True, pa, 100  \n",
       "3  False, 0, False, pa, 100  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters\n",
    "parameters = {\n",
    "    \"algorithm\": ['pa'],\n",
    "    \"max_iterations\": [100],\n",
    "    'pa_type': [0],\n",
    "    'error_sensitive':[True,False],\n",
    "    'averaging': [True,False] \n",
    "}\n",
    "\n",
    "#tune\n",
    "clf, results = train_tune_classifier(parameters, X_train, y_train, verbose=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be observed, the  of best scores are characterized for having the averaging parameter set to True. The two of them have a mean test score greater than 0.75 while the other ones are aroung 0.71.\n",
    "\n",
    "Let's look how it performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.800     0.753     0.776      1084\n",
      "     B-MISC      0.683     0.566     0.619       339\n",
      "      B-ORG      0.815     0.841     0.827      1400\n",
      "      B-PER      0.809     0.876     0.841       735\n",
      "      I-LOC      0.730     0.640     0.682       325\n",
      "     I-MISC      0.707     0.562     0.626       557\n",
      "      I-ORG      0.855     0.793     0.823      1104\n",
      "      I-PER      0.885     0.935     0.910       634\n",
      "\n",
      "avg / total      0.804     0.780     0.790      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print metrics.flat_classification_report(y_test, y_pred, labels=sorted(labels), digits=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there a slight improvement on the precision score. \n",
    "\n",
    "### Tuning number of rounds\n",
    "\n",
    "Finally we are going to tune the number of rounds or max_iterations. We are going to test on a wide range of iterations to see how the scores change as we increase the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30, total=  10.0s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30, total=   9.6s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30, total=  10.6s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=30, total=   9.8s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50, total=  14.0s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50, total=  13.6s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50, total=  13.7s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=50, total=  13.9s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80, total=  17.8s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80, total=  17.8s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80, total=  17.3s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=80, total=  18.0s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  20.3s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  20.8s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  21.1s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  21.6s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200 \n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200, total=  39.6s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200, total= 8.6min\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200, total=  47.8s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=200, total=  42.3s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400 \n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400, total= 1.5min\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400, total= 1.5min\n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400, total= 1.3min\n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=400, total=  59.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'averaging': True, 'pa_type': 0, 'error_sensitive': True, 'algorithm': 'pa', 'max_iterations': 80}\n",
      "Best Score: 0.7594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.122290</td>\n",
       "      <td>0.629203</td>\n",
       "      <td>0.759442</td>\n",
       "      <td>0.964307</td>\n",
       "      <td>True, 0, True, pa, 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.343756</td>\n",
       "      <td>0.627374</td>\n",
       "      <td>0.759349</td>\n",
       "      <td>0.967521</td>\n",
       "      <td>True, 0, True, pa, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.748758</td>\n",
       "      <td>1.033526</td>\n",
       "      <td>0.759193</td>\n",
       "      <td>0.956491</td>\n",
       "      <td>True, 0, True, pa, 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.379437</td>\n",
       "      <td>0.620304</td>\n",
       "      <td>0.758696</td>\n",
       "      <td>0.941845</td>\n",
       "      <td>True, 0, True, pa, 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160.366154</td>\n",
       "      <td>0.948598</td>\n",
       "      <td>0.754008</td>\n",
       "      <td>0.973328</td>\n",
       "      <td>True, 0, True, pa, 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.943230</td>\n",
       "      <td>0.941614</td>\n",
       "      <td>0.749681</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>True, 0, True, pa, 400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "2      17.122290         0.629203         0.759442          0.964307   \n",
       "3      20.343756         0.627374         0.759349          0.967521   \n",
       "1      12.748758         1.033526         0.759193          0.956491   \n",
       "0       9.379437         0.620304         0.758696          0.941845   \n",
       "4     160.366154         0.948598         0.754008          0.973328   \n",
       "5      78.943230         0.941614         0.749681          0.975045   \n",
       "\n",
       "                   params  \n",
       "2   True, 0, True, pa, 80  \n",
       "3  True, 0, True, pa, 100  \n",
       "1   True, 0, True, pa, 50  \n",
       "0   True, 0, True, pa, 30  \n",
       "4  True, 0, True, pa, 200  \n",
       "5  True, 0, True, pa, 400  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters\n",
    "parameters = {\n",
    "    \"algorithm\": ['pa'],\n",
    "    \"max_iterations\": [30,50,80,100,200,400],\n",
    "    'pa_type': [0],\n",
    "    'error_sensitive':[True],\n",
    "    'averaging': [True] \n",
    "}\n",
    "\n",
    "#tune\n",
    "clf, results = train_tune_classifier(parameters, X_train, y_train, verbose=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe the best number of iterations is 80. A bigger number and the \n",
    "Let's evaluate the model against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.792     0.757     0.774      1084\n",
      "     B-MISC      0.690     0.552     0.613       339\n",
      "      B-ORG      0.809     0.836     0.822      1400\n",
      "      B-PER      0.808     0.868     0.837       735\n",
      "      I-LOC      0.720     0.649     0.683       325\n",
      "     I-MISC      0.726     0.548     0.624       557\n",
      "      I-ORG      0.853     0.804     0.828      1104\n",
      "      I-PER      0.886     0.934     0.909       634\n",
      "\n",
      "avg / total      0.803     0.779     0.789      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print metrics.flat_classification_report(y_test, y_pred, labels=sorted(labels), digits=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So actually the model overfitted a little bit and we got a slightly lower score. Probably we will need to relax the tuning a little bit by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70, total=  21.3s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70, total=  18.3s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70, total=  17.7s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=70, total=  19.0s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90, total=  22.1s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90, total=  22.9s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90, total=  26.8s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=90, total=  21.1s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  25.0s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  23.0s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  22.1s\n",
      "[CV] averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100 \n",
      "[CV]  averaging=True, pa_type=0, error_sensitive=True, algorithm=pa, max_iterations=100, total=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:  6.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'averaging': True, 'pa_type': 0, 'error_sensitive': True, 'algorithm': 'pa', 'max_iterations': 100}\n",
      "Best Score: 0.7598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.597318</td>\n",
       "      <td>0.655407</td>\n",
       "      <td>0.759790</td>\n",
       "      <td>0.967175</td>\n",
       "      <td>True, 0, True, pa, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.392606</td>\n",
       "      <td>0.680045</td>\n",
       "      <td>0.759365</td>\n",
       "      <td>0.962603</td>\n",
       "      <td>True, 0, True, pa, 70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.765723</td>\n",
       "      <td>1.450070</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>0.966271</td>\n",
       "      <td>True, 0, True, pa, 90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "2      22.597318         0.655407         0.759790          0.967175   \n",
       "0      18.392606         0.680045         0.759365          0.962603   \n",
       "1      21.765723         1.450070         0.759000          0.966271   \n",
       "\n",
       "                   params  \n",
       "2  True, 0, True, pa, 100  \n",
       "0   True, 0, True, pa, 70  \n",
       "1   True, 0, True, pa, 90  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters\n",
    "parameters = {\n",
    "    \"algorithm\": ['pa'],\n",
    "    \"max_iterations\": [70,90,100],\n",
    "    'pa_type': [0],\n",
    "    'error_sensitive':[True],\n",
    "    'averaging': [True] \n",
    "}\n",
    "\n",
    "#tune\n",
    "clf, results = train_tune_classifier(parameters, X_train, y_train, verbose=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.802     0.757     0.779      1084\n",
      "     B-MISC      0.680     0.563     0.616       339\n",
      "      B-ORG      0.810     0.843     0.826      1400\n",
      "      B-PER      0.815     0.873     0.843       735\n",
      "      I-LOC      0.725     0.634     0.677       325\n",
      "     I-MISC      0.713     0.558     0.626       557\n",
      "      I-ORG      0.854     0.798     0.825      1104\n",
      "      I-PER      0.889     0.931     0.909       634\n",
      "\n",
      "avg / total      0.805     0.781     0.791      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print metrics.flat_classification_report(y_test, y_pred, labels=sorted(labels), digits=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we had a slightly better score. In the end we improved the model by 0.005 on the f1-score. Not much, but good enough for the features we used.\n",
    "\n",
    "# Conclusion\n",
    "We've learned how to train and tune a CRF using the sklearn-crfsuite library. With it we extracted the labels for named entities.  \n",
    "\n",
    "Next steps would be to create better features, select the best ones, tune again the model and evaluate the score."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
