{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "In this notebook we are gonna attempt to train a HMM (Hiden Markov Model). The goal is make an HMM that will recognize Named Entities.\n",
    "\n",
    "For this notebook we are going to use the HMM tagger from NLTK which has a trainer and implements the Viterbi Algorithm to generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HMM Theory\n",
    "Before starting let's birefly review a little bit about HMM:   \n",
    "( Summary based on this lecture:  https://www.cs.bgu.ac.il/~elhadad/nlp11/prob/postagging.pdf )\n",
    "\n",
    "One common use for HMM is to solve the Part of Speech problem defined as:   \n",
    "**Given a word sequence $w_1, w_2, w3 .. w_m$  determine the corresponding POS tag sequence  $t_1, t_2, t_3 .. t_m$**\n",
    "\n",
    "### Problem statement from a probabilistic point of view\n",
    "\n",
    "Find the most probable sequence of tags for a given sequence of words: \n",
    "\n",
    "$$argmax_{t_1..t_m}P(t_1..t_m | w_1 .. w_m)$$  \n",
    "Applying Bayes Theorem we can re-define:   \n",
    "$$= argmax_{t_1..t_m}\\frac{P(t_1..t_m)P(w_1..w_m|t_1..t_m)}{P(w_1..w_m)}$$   \n",
    "$$= argmax_{t_1..t_m}{P(t_1..t_m)P(w_1..w_m|t_1..t_m)}$$\n",
    "\n",
    "\n",
    "\n",
    "The resulting expression can be read as: Find the sequence of tags t1..tm that is more likely to appear in a text and produce the sequence of words w1..wm. \n",
    "\n",
    "### Independence assumptions\n",
    "There are some assumptions made that constrain the problem:\n",
    "- Contextual Model: Tags are dependent only on the precedent tags.\n",
    "- Lexical Model: Words are dependent only on their own part-of-speech tag.\n",
    "\n",
    "Thus the problem expression changes to:\n",
    "$$= argmax_{t_1..t_m} \\prod_{i=1}^{m}P(t_i|t_{i-1})P(w_i|t_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a HMM help in solving the problem?\n",
    "Well the hmm fits this problem perfectly.   \n",
    "**A HMM consists of 5 parts**\n",
    "- a finite set of states  *States = { $s_1 ... s_k$ }*  these are the tags.\n",
    "- a finite set of signal alphabet *Signals = { $o_1 .. o_m$ }* these are the possible words.\n",
    "- Initial probabilities *$P(s)$ for every s in States*. i.e. the probability of starting on s.\n",
    "- Transition probabilities *$P( s_i | s_j )$*\n",
    "- Emission probabilities   *$P( o | s )$*\n",
    "\n",
    "**The state transitions are assumed dependent only on the state   \n",
    "(just as the Contextual Model of POS)**\n",
    "\n",
    "$$P(s_1..s_n) = \\prod_{i=1}^n P(s_i | s_{i-1} ) )$$ \n",
    "\n",
    "** Signal emmisions are assumed to be dependent only on the current states   \n",
    "(just as Lexical Model of the POS)**\n",
    "\n",
    "$$ P( s_1..s_n, o_1, o_n ) = \\prod_{i=1}^n P(s_i | s_{i-1} ) P(o_i | s_i )$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Estimation\n",
    "So, we got a model that fits the description of the problem, now what?   \n",
    "Answer: Well, let's see what we have according to the problem statement:   \n",
    "**What we have:**\n",
    "- A sequence of words which we can be considered as signal emissions.\n",
    "- A sequence of POS tags which we can be considered as the corresponding states (only for supervised learning).\n",
    "- The signal alphabet which is the set of unique words.\n",
    "- The states which is the set of unique POS tags (only for supervised learning).\n",
    "\n",
    "**What we don't have and is missing to complete the model:**\n",
    "- The Initial probabilities\n",
    "- The Transitions probabilities\n",
    "- The Emission probabilities\n",
    "\n",
    "There are two approaches to obtain these probabilities:\n",
    "- **Supervised Learning:** Using frequency counts from a tagged corpus in order to use a MLE estimator(Maximum Likelihood Estimation)\n",
    "- **Unsupervised Learning:** Use an expectation-maximization algorithm from an untagged corpus.\n",
    "\n",
    "For this notebook we're gonna focus on the supervised learning using MLE.\n",
    "\n",
    "#### Maximum Likelihood Estimation\n",
    "\n",
    "This is a fairly simple task to do:\n",
    "\n",
    "**Initial and Transition probabilities**  \n",
    "$$\\hat{P}(s_i | s_{i-1} ) = \\frac{Count(s_{i-1}, s_i)}{Count(s_{i-1})} $$   \n",
    "**Emission probabilities**    \n",
    "$$\\hat{P}(o | s ) = \\frac{Count(o, s)}{Count(s)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging\n",
    "\n",
    "Great! So now we have all the components of the Hidden Markov Model. Are we done? No.    \n",
    "Let's remember the initial task:\n",
    "> **Given a word sequence $w_1, w_2, w_3 .. w_m $ determine the corresponding POS tag sequence  $t_1, t_2, t_3 .. t_m$**    \n",
    "$$argmax_(t_1..t_m) \\prod_{i=1}^m P(t_i) P(w_i|t_i) $$\n",
    "\n",
    "We need to find the tags (aka the states) that maximize the expression! \n",
    "\n",
    "A common algorithm to solve the maximization problem in HMM is called the Viterbi Algorithm. Given a sequence of signals, the Viterbi algorithm finds the optimal path in a HMM (i.e. the path that that maximizes the Probability of producing the signal sequence). The Viterbi algorithm does this by applying dynamic programming techniques instead of analyzing every possible path.\n",
    "\n",
    "In the inside the Viterbi algorithm uses a trellis with nodes that represent the possible states at each step. Using the trellis the algorithm then proceeds to calculate the probability of being in each state at each step. At the same time the algorithm saves into a back-pointer the edge with the maximum probability of transitioning from one step-state to another step-state. After finishing the Viterbi algorithm just follows the maximum back-pointers path from the end to the start node, thus giving us the states that maximize the probability of producing the signal sequence.\n",
    "\n",
    "More details on the Viterbi algorithm can be found here: \n",
    "http://web.mit.edu/6.02/www/f2010/handouts/lectures/L9.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hands-on: Clone the NLTK POS tagging demo\n",
    "In order to understand how to use the nltk hmm first we're gonna clone the nltk Part-of-Speech (POS) tagging demo found in \n",
    "http://www.nltk.org/_modules/nltk/tag/hmm.html#demo_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing the demo does is call the function *load_pos( )*. That function basically gets and preprocess the data.\n",
    "\n",
    "So unwrapping the function, first we are going to import the brown corpus and limit it to a number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextabora/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# general purpose libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import the brown corpuz\n",
    "from nltk.corpus import brown\n",
    "\n",
    "num_sentences = 10000\n",
    "\n",
    "#using simplified tagset instead of \"cleaning\" the tags\n",
    "sentences = brown.tagged_sents(categories='news', tagset='universal')[:num_sentences]  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we are going to normalize the words and generate a vocabulary set and a tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag set length: 12\n",
      "vocabulary set length: 13112\n",
      "sentences length: 4623\n"
     ]
    }
   ],
   "source": [
    "tag_set = set()\n",
    "vocab_set = set()\n",
    "norm_sentences = []\n",
    "\n",
    "for sent in sentences:\n",
    "    for idx, word in enumerate(sent):\n",
    "        #normalize the word\n",
    "        norm_word = word[0].lower()  \n",
    "        #add to sets\n",
    "        vocab_set.add(norm_word)\n",
    "        tag_set.add(word[1])\n",
    "        #modify the sentence\n",
    "        sent[idx] = (norm_word, word[1])\n",
    "    #add sentence to new list\n",
    "    norm_sentences += [sent]\n",
    "    \n",
    "    \n",
    "print \"tag set length: %i\" %len(tag_set)\n",
    "print \"vocabulary set length: %i\" %len(vocab_set)\n",
    "print \"sentences length: %i\" %len(norm_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's take a sneak peek to the tag set and the vocabulary sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag Set:\n",
      "set([u'ADV', u'NOUN', u'ADP', u'PRON', u'DET', u'.', u'PRT', u'VERB', u'X', u'NUM', u'CONJ', u'ADJ'])\n",
      "\n",
      "Vocabulary Set (first 10):\n",
      "[u'sunbonnet', u'yellow', u'narcotic', u'four', u'woods', u'boogie', u'railing', u'francesca', u'aggression', u'marching']\n"
     ]
    }
   ],
   "source": [
    "print \"Tag Set:\"\n",
    "print tag_set\n",
    "print \n",
    "print \"Vocabulary Set (first 10):\"\n",
    "print list(vocab_set)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems in order, the tag set values are the POS tags which we wish to predict and the vocabulary set has the  unique words but in lower case.\n",
    "\n",
    "### Training the HMM tagger\n",
    "\n",
    "Ok, so to train the model we need to create an instance of a HMM Trainer. The trainer contains functions that generate the model either by **Supervised Learning using MLE (Maximum Likelihood Estimation)** or **Unsupervised Learning using Baum-Welch Algorithm**.  \n",
    "\n",
    "The init function for HMM trainer has the following inputs:\n",
    "- **states:** these are the tags \n",
    "- **symbols:** this is the word vocabulary \n",
    "\n",
    "We are going to use the *train_supervised()* method in order to train the model (aka estimate the HMM probabilities) using the MLE algorithm. This is just as we discussed in the theoretical summary :) \n",
    "\n",
    "Finally we will test the model accuracy with the *test()* method. Notice that for this simple example only 10 sentences were used as a testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 284 tokens: 53.52\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import HiddenMarkovModelTrainer\n",
    "trainer = HiddenMarkovModelTrainer(states=tag_set, symbols=vocab_set)\n",
    "\n",
    "#training the model using the default MLE\n",
    "hmm = trainer.train_supervised(norm_sentences[10:])\n",
    "#testing the model\n",
    "hmm.test(norm_sentences[:10], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy is low. To get a better score we can use a smoothed probability estimator.\n",
    "\n",
    "To smooth the MLE estimation we are gonna override the estimator using a Lidstone estimator (additive smoothing). \n",
    "https://en.wikipedia.org/wiki/Additive_smoothing\n",
    "\n",
    "This estimator basically assumes that there are no event probability = 0 by adding a value to the nominator.\n",
    "\n",
    "$$ O_i = \\frac{x_i + gamma}{N+ d*gamma}$$ where $0 <= gamma <=1$ and $i$ in $1..d$ (d is the number of bins)\n",
    "\n",
    "The smoothed probability will be in between the empirical estimate $\\frac{count(x)}{N}$ and the uniform probability $\\frac{1}{d}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 284 tokens: 93.66\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import LidstoneProbDist\n",
    "#training with another estimator\n",
    "hmm = trainer.train_supervised(\n",
    "    norm_sentences[10:],\n",
    "    estimator= lambda fd, bins: LidstoneProbDist(fd, 0.1, bins)\n",
    ")\n",
    "#testing the model\n",
    "hmm.test(norm_sentences[:10], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is quite of an improvement for the model.\n",
    "\n",
    "We have now successfully cloned the demo. It is time to do a challenge by ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Challenge\n",
    "\n",
    "The challenge is to use the hmm tagger to recognize Named Entities (NE).\n",
    "\n",
    "For this challenge we are going to use the spanish set of the conll2002 corpus. (At this moment it was the only NE tagged corpus in I found in NLTK )\n",
    "\n",
    "The nice thing about this corpus is that it has already splitted a train and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train: 8323\n",
      "number of test: 1517\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2002\n",
    "train_sents = list(conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(conll2002.iob_sents('esp.testb'))\n",
    "print \"number of train: %i\" %len(train_sents)\n",
    "print \"number of test: %i\" %len(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a sneak peek of how the sentences look "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Melbourne', u'NP', u'B-LOC'),\n",
       " (u'(', u'Fpa', u'O'),\n",
       " (u'Australia', u'NP', u'B-LOC'),\n",
       " (u')', u'Fpt', u'O'),\n",
       " (u',', u'Fc', u'O'),\n",
       " (u'25', u'Z', u'O'),\n",
       " (u'may', u'NC', u'O'),\n",
       " (u'(', u'Fpa', u'O'),\n",
       " (u'EFE', u'NC', u'B-ORG'),\n",
       " (u')', u'Fpt', u'O'),\n",
       " (u'.', u'Fp', u'O')]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe each word has 3 fields:\n",
    "- The word\n",
    "- The Part-of-Speech Tag\n",
    "- The IOB tag with the NE type\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "So let's recall what we need: \n",
    "- The symbols\n",
    "- The states  \n",
    "- A labeled sequence. \n",
    "\n",
    "In this case the symbols are going to be a tuple of two features:  ( Word , POS tag )   \n",
    "*Note: we are using only two features for this simple challenge you can experiment adding more features... I'll certainly will do in another notebook ;) *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function preprocesses the array of sentences and return the symbols and states\n",
    "def preprocess_conll(sents):\n",
    "    symbols = set()\n",
    "    states = set()\n",
    "    \n",
    "    for sent in sents:\n",
    "        for idx, word in enumerate(sent):\n",
    "            #normalize the word\n",
    "            norm_word = word[0].lower()  \n",
    "            #add to sets\n",
    "            symbols.add( (norm_word, word[1]) ) #in this case the symbol is a tuple of features\n",
    "            states.add(word[2])\n",
    "            \n",
    "            #modify the sentence\n",
    "            sent[idx] = ( (norm_word, word[1] ), word[2])\n",
    "    \n",
    "    return symbols, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of symbols: 26726\n",
      "number of states: 9\n"
     ]
    }
   ],
   "source": [
    "#train set\n",
    "symbols, states =  preprocess_conll(train_sents)\n",
    "#test set\n",
    "preprocess_conll(test_sents)\n",
    "\n",
    "print \"number of symbols: %i\" %len(symbols)\n",
    "print \"number of states: %i\" %len(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a sneak peek to the data to be sure everything is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- states -- \n",
      "set([u'I-LOC', u'B-ORG', u'I-PER', u'O', u'I-MISC', u'B-MISC', u'I-ORG', u'B-LOC', u'B-PER'])\n",
      "\n",
      "-- symbols (first 10) -- \n",
      "[(u'!', u'Fat'), (u'\"', u'Fe'), (u'\"bike-\\xe1rea\"', u'NC'), (u'\"ch\\xe9\"', u'AQ'), (u'\"macho\"', u'AQ'), (u'\"sharia\"', u'NC'), (u'%', u'Ft'), (u'%var', u'AQ'), (u\"'\", u'Fz'), (u\"'18\", u'Z')]\n"
     ]
    }
   ],
   "source": [
    "print \"-- states -- \"\n",
    "print states\n",
    "print\n",
    "print \"-- symbols (first 10) -- \"\n",
    "print sorted(list(symbols))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the HMM \n",
    "\n",
    "Just like before let's repeat the code to train a Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Creating Trainer\n",
      "- Training\n",
      "- Testing\n",
      "accuracy over 3711 tokens: 93.56\n"
     ]
    }
   ],
   "source": [
    "print \"- Creating Trainer\"\n",
    "NE_trainer = HiddenMarkovModelTrainer(states= NE_tag_set, symbols= NE_vocab_set)\n",
    "\n",
    "#training with another estimator\n",
    "print \"- Training\"\n",
    "NE_hmm = NE_trainer.train_supervised(\n",
    "    train_sents,\n",
    "    estimator= lambda fd, bins: LidstoneProbDist(fd, 0.1, bins)\n",
    ")\n",
    "\n",
    "print \"- Testing\"\n",
    "#testing the model limited to 100 because of performance issues\n",
    "NE_hmm.test(test_sents[:100], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deceiving scores....\n",
    "So by the looks everything is doing great with the **93.56% of accuracy!**. However the truth is, that we cannot just go with the accuracy score. We should look deeper into the data and the scores.\n",
    "\n",
    "Let's check if the classes are unbalanced.. ( I always get this bad feeling about overly optimistic scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAGHCAYAAADY7Nq0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114516190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iob_tags = []\n",
    "for sent in test_sents[:100]:    \n",
    "    iob_tags += [ str(w[1]) for w in sent]\n",
    "    \n",
    "iob_tags = pd.Series(iob_tags)\n",
    "iob_tags.value_counts().plot('bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! As we can see in the graph, the classes are really unbalanced, specially in the 'O' class. In this cases is better to use other scoring methods like precision, recall and f-score.  \n",
    "\n",
    "## Other scoring methods...\n",
    "\n",
    "Fortunately sklearn has a function that called classification_report that can shows us what's really happening. \n",
    "\n",
    "Below we're gonna use the tag() method from HMM to get the predictions and compare them with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tagging (Predicting)\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.65      0.55      0.59        73\n",
      "     B-MISC       0.26      0.22      0.24        23\n",
      "      B-ORG       0.84      0.72      0.77       116\n",
      "      B-PER       0.76      0.64      0.69        55\n",
      "      I-LOC       0.80      0.55      0.65        22\n",
      "     I-MISC       0.22      0.33      0.27        24\n",
      "      I-ORG       0.64      0.69      0.66        91\n",
      "      I-PER       0.75      0.88      0.81        49\n",
      "          O       0.97      0.98      0.97      3258\n",
      "\n",
      "avg / total       0.94      0.94      0.94      3711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print \"- Tagging (Predicting)\"\n",
    "words = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "for sent in test_sents[:100]:\n",
    "    words += [w[0] for w in sent]\n",
    "    true_labels += [w[1] for w in sent]\n",
    "    sent_preds = NE_hmm.tag([w[0] for w in sent])\n",
    "    pred_labels += [w[1] for w in sent_preds]\n",
    "print \n",
    "print classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, on many classes the f1-score is low with values as low as 0.24. What's happening with our accuracy is that the class label 'O' has many positive samples (3,258) and this is affecting the overall score.\n",
    "\n",
    "If we ignore that class label, which is not the focus of what we are trying to classify the average results change drastically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.65      0.55      0.59        73\n",
      "     B-MISC       0.26      0.22      0.24        23\n",
      "      B-ORG       0.84      0.72      0.77       116\n",
      "      B-PER       0.76      0.64      0.69        55\n",
      "      I-LOC       0.80      0.55      0.65        22\n",
      "     I-MISC       0.22      0.33      0.27        24\n",
      "      I-ORG       0.64      0.69      0.66        91\n",
      "      I-PER       0.75      0.88      0.81        49\n",
      "\n",
      "avg / total       0.68      0.64      0.66       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(true_labels, pred_labels, labels=sorted(list(NE_tag_set))[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a f1-score of .66 is not very good, but for this simple challenge it seems ok. Probably adding more relevant features will make the score go higher (e.g. Capitalized words, N-grams, gazetteer, trigger words etc... ).\n",
    "\n",
    "## Entity based scoring\n",
    "So far, the score has been based on the IOB tags for entities, but the real goal of NE tagging is to be able to recognize the entities. Therefore, we should score on how many entities did the model find. \n",
    "\n",
    "One common approach to score on an entity basis is to consider only complete entities as correct and partial recognized entities as incorrect. Having said that, we must keep in mind that a mistake of a partial entity will cause a double penalty since it will be accounted as a false positive and a false negative which seems fine to many academic literature.\n",
    "\n",
    "In the code below, the entities are extracted using the IOB tags (label and pred) and then it is measured wether the model recognized correctly an entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entity Based Report ---\n",
      "precision: 0.7522\n",
      "recall: 0.6367\n",
      "f_score: 0.6897\n",
      "support: 267.0000\n"
     ]
    }
   ],
   "source": [
    "#function that extracts the entities using the IOB tags\n",
    "def get_entities(df, column):\n",
    "    data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[column][0] == \"B\":\n",
    "            data.append([idx, row.word[0]])\n",
    "        elif row[column][0] == \"I\":\n",
    "            data[-1][1] += \" \" + row.word[0]\n",
    "    return data\n",
    "    \n",
    "\n",
    "# Function that extracts entities using the labels and predictions, \n",
    "# then compares both list of entities and counts the correct and incorrect predictions, and the missed predictions.\n",
    "def score_entities(words, true_labels, pred_labels):\n",
    "    \n",
    "    # extract the entities\n",
    "    df = pd.DataFrame({\n",
    "        \"word\": words,\n",
    "        \"label\":true_labels,\n",
    "        \"pred\": pred_labels\n",
    "    })\n",
    "    true_entities = get_entities(df, \"label\")\n",
    "    pred_entities = get_entities(df, \"pred\")\n",
    "    \n",
    "    \n",
    "    #count the correct and incorrect predictions, nd the missed predictions.\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    #look if the predicted entity is in the gold standard.\n",
    "    for entity in pred_entities:\n",
    "        if entity in true_entities:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    #look for any missed prediction\n",
    "    for entity in true_entities:\n",
    "        if entity not in pred_entities:\n",
    "            fn += 1\n",
    "            \n",
    "    #calculate the scores and print them\n",
    "    precision = tp * 1.0 / (tp+fp)\n",
    "    recall = tp * 1.0 / (tp+fn)\n",
    "    f_score = 2.0 * precision * recall / (precision + recall)\n",
    "    support = len(true_entities)\n",
    "    \n",
    "    print \"--- Entity Based Report ---\"\n",
    "    print \"precision: %0.4f\" %precision\n",
    "    print \"recall: %0.4f\" %recall\n",
    "    print \"f_score: %0.4f\" %f_score\n",
    "    print \"support: %0.4f\" %support\n",
    "    \n",
    "    \n",
    "score_entities(words, true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "As we can observe the model correctly identified ~64% of the Named Entities using only 2 features (which personally I find it not bad at all). The final f-score is of ~69% which probably can be improved by adding better features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook we succesfully trained a HMM classifier using the NLTK library and with it we were able to use it for Named Entity Recognition. \n",
    "\n",
    "We've also learned that its better to score the results using more robust scoring methods such as precision, recall and f1. \n",
    "\n",
    "Finally, we scored the HMM results on identifying Named Entities instead of just the tags."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
